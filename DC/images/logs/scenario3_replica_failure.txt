============================================================
   SCENARIO 3: REPLICA FAILURE DURING WRITE
============================================================

This demonstrates graceful degradation using Cabinet's quorum 
selection when a replica fails during write operations.

>>> INITIAL STATE:
    Master:   mysql-instance-4
    Replicas: mysql-instance-2, mysql-instance-3
    Quorum requirement: 1 of 2 replicas must catch up

>>> STEP 1: Replica fails unexpectedly
    Command: docker stop mysql-instance-2
    Result: mysql-instance-2 container stopped
    
    [docker output]: mysql-instance-2

>>> STEP 2: Metrics Collector detects unhealthy replica
    Metrics polling cycle: every 5 seconds
    
    GET http://metrics-collector:8000/metrics
    Response:
    ┌─────────────┬────────────┬──────────────┐
    │ Instance    │ Status     │ Latency      │
    ├─────────────┼────────────┼──────────────┤
    │ instance-1  │ ✗ UNHEALTHY│ 9999.00ms    │
    │ instance-2  │ ✗ UNHEALTHY│ 9999.00ms    │
    │ instance-3  │ ✓ HEALTHY  │ 6.77ms       │
    │ instance-4  │ ✓ HEALTHY  │ 6.07ms       │
    └─────────────┴────────────┴──────────────┘
    
    Note: instance-1 was already down from previous failover scenario

>>> STEP 3: Cabinet selects quorum excluding unhealthy replicas
    POST http://cabinet-service:8000/select-quorum
    Body: { "quorum_size": 2 }
    
    Cabinet Algorithm Logic:
    - Filters out replicas with is_healthy=false
    - Assigns weight=0 to unhealthy replicas
    - Selects top N by weighted score
    
    Response: {
      "quorum": ["instance-3"],
      "quorum_size": 1,
      "total_replicas": 4
    }
    
    Note: Only instance-3 is healthy and available as replica

>>> STEP 4: Write operation succeeds with reduced quorum
    POST http://coordinator:8000/query
    Body: {
      "query": "INSERT INTO products (name, price) VALUES ('Quorum Test', 59.99)",
      "consistency": "STRONG"
    }
    
    Execution Flow:
    a) Coordinator gets timestamp: 111 from timestamp-service-1
    b) Write executed on master (instance-4)
    c) Cabinet returns quorum: [instance-3]
    d) Coordinator waits for instance-3 to catch up
    e) instance-3 confirms timestamp >= 111
    f) Quorum achieved with 1/1 healthy replicas
    
    [coordinator logs]:
    timestamp-service-1  | GET /timestamp HTTP/1.1 200 OK
    cabinet-service      | POST /select-quorum HTTP/1.1 200 OK
    coordinator          | POST /query HTTP/1.1 200 OK
    
    Response: {
      "success": true,
      "message": "Write successful (consistency: STRONG, timestamp: 111, 
                  Cabinet replicas: instance-3)",
      "timestamp": 111,
      "rows_affected": 1,
      "executed_on": "mysql-instance-4",
      "consistency_level": "STRONG",
      "latency_ms": 62.68,
      "quorum_achieved": true,
      "replica_caught_up": true
    }

============================================================
   KEY OBSERVATIONS
============================================================

✓ Metrics Collector detected instance-2 failure within 5 seconds
✓ Cabinet automatically excluded unhealthy instance-2 from quorum
✓ Write succeeded with remaining healthy replica (instance-3)
✓ Quorum still satisfied: 1 of 1 available replicas caught up
✓ No data loss - write persisted to master and healthy replica
✓ Total operation latency: 62.68ms (slightly higher due to smaller quorum)

============================================================
   FAILURE HANDLING
============================================================

• System continues operating with reduced capacity
• Quorum dynamically adjusts to available healthy replicas
• When instance-2 recovers, it will:
  1. Reconnect to master via binlog replication
  2. Catch up on missed transactions
  3. Be re-added to Cabinet's quorum selection pool

